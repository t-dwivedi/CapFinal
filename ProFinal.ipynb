{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSST22ipAPgF5IUerEnmOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-dwivedi/CapFinal/blob/main/ProFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pathway bokeh --quiet"
      ],
      "metadata": {
        "id": "Yyeqhx08Zc2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "rqwf_vu9Wn1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"dataset.csv\")\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "EyOVXUM2XmBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "import pathway as pw\n",
        "import bokeh.plotting\n",
        "import panel as pn"
      ],
      "metadata": {
        "id": "cD3p8tjsb__n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_names_list = data['TrafficConditionNearby'].unique().tolist()\n",
        "print(\"Unique names as list:\", unique_names_list)"
      ],
      "metadata": {
        "id": "9Oud_UL4T6ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_names_list = data['SystemCodeNumber'].unique().tolist()\n",
        "print(\"Unique names as list:\", unique_names_list)"
      ],
      "metadata": {
        "id": "gJWSuFp_hbNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding categorical data\n",
        "# Define the mapping dictionary\n",
        "traffic_map = {\n",
        "    \"low\": 0.0,\n",
        "    \"average\": 0.5,\n",
        "    \"high\": 1.0\n",
        "}\n",
        "\n",
        "# Applying the mapping to create a new column in your DataFrame\n",
        "data[\"TrafficLevel\"] = data[\"TrafficConditionNearby\"].map(traffic_map)\n"
      ],
      "metadata": {
        "id": "CO9TChqtQTF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_names_list = data['VehicleType'].unique().tolist()\n",
        "print(\"Unique names as list:\", unique_names_list)"
      ],
      "metadata": {
        "id": "yBAOl-IjVeDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"OccupancyRate\"] = data[\"Occupancy\"]/ data[\"Capacity\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "N6G_NhMyXMsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vehicle_type_weight = {\n",
        "    \"cycle\": 0.3,\n",
        "    \"bike\": 0.5,\n",
        "    \"car\": 1.0,\n",
        "    \"truck\": 1.5\n",
        "}\n",
        "\n",
        "# Applying the mapping to create the VehicleTypeWeight column\n",
        "data[\"VehicleTypeWeight\"] = data[\"VehicleType\"].map(vehicle_type_weight)\n"
      ],
      "metadata": {
        "id": "AUAqbKSZVwUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "BY9EVoIh7PO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title Capacity\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "data['Capacity'].plot(kind='hist', bins=20, title='Capacity')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "jrDYn3lBgz44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_price=10\n",
        "alpha=5\n",
        "data[\"Model1_Price\"]=base_price + alpha*data[\"OccupancyRate\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "u2cZsD4xd22v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "min_price, max_price = 5, 20\n",
        "\n",
        "out_of_range_rows = data[(data[\"Model1_Price\"] < min_price) | (data[\"Model1_Price\"] > max_price)]\n",
        "\n",
        "print(f\"Number of out-of-range rows: {len(out_of_range_rows)}\")\n",
        "display(out_of_range_rows)\n"
      ],
      "metadata": {
        "id": "T7R4Cc8_kHMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary statistics for OccupancyRate:\")\n",
        "print(data[\"OccupancyRate\"].describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "CQfPGDhuh6WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "lot_code = 'Shopping'\n",
        "lot_data = data[data[\"SystemCodeNumber\"] == lot_code].copy()\n",
        "\n",
        "lot_data['Timestamp'] = pd.to_datetime(\n",
        "    lot_data['LastUpdatedDate'] + ' ' + lot_data['LastUpdatedTime'],\n",
        "    format='%d-%m-%Y %H:%M:%S'\n",
        ")\n",
        "\n",
        "lot_data.sort_values('Timestamp', inplace=True)\n",
        "\n",
        "\n",
        "source = ColumnDataSource(lot_data)\n",
        "\n",
        "p = figure(title=f\"Model 1 Price Evolution for {lot_code}\",\n",
        "           x_axis_type='datetime',\n",
        "           x_axis_label='Time',\n",
        "           y_axis_label='Price ($)',\n",
        "           outer_width=900, outer_height=400)\n",
        "\n",
        "p.line(x='Timestamp', y='Model1_Price', source=source, line_width=2, color='navy', legend_label=\"Model1 Price\")\n",
        "\n",
        "p.legend.location = \"top_left\"\n",
        "p.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "c_mB3ESCgUgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Baseline Linear Pricing\n",
        "\n",
        "In this model, we calculate parking prices based solely on occupancy rate.\n",
        "\n",
        "**Formula:**  \n",
        "Price = BasePrice + alpha × OccupancyRate\n",
        "\n",
        "- Base price is set at $10.\n",
        "\n",
        "- Alpha is chosen as 5 after testing several values to balance price sensitivity with stability.\n",
        "\n",
        "- Prices are clamped between $5 (0.5× base) and $20 (2× base), as required by the problem statement.\n",
        "\n",
        "**Findings:**\n",
        "\n",
        "- Plots show price increases and decreases no so smoothly but a linear model can give only this much smoothness and further development in model will get better results.\n",
        "\n",
        "- No prices exceed the allowed range, confirming the model behaves as expected.\n"
      ],
      "metadata": {
        "id": "v-KZjoH0nwIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pathway as pw\n",
        "\n",
        "data['Timestamp'] = pd.to_datetime(\n",
        "    data['LastUpdatedDate'] + ' ' + data['LastUpdatedTime'],\n",
        "    format='%d-%m-%Y %H:%M:%S'\n",
        ")\n",
        "\n",
        "data.sort_values('Timestamp', inplace=True)\n",
        "\n",
        "data[['Timestamp', 'Occupancy', 'Capacity']].to_csv(\n",
        "    'parking_stream.csv', index=False\n",
        ")\n",
        "\n",
        "class ParkingSchema(pw.Schema):\n",
        "    Timestamp: str\n",
        "    Occupancy: int\n",
        "    Capacity: int\n",
        "\n",
        "source = pw.demo.replay_csv(\n",
        "    'parking_stream.csv',\n",
        "    schema=ParkingSchema,\n",
        "    input_rate=100\n",
        ")\n",
        "\n",
        "occupancy_rate = source.Occupancy / source.Capacity\n",
        "model1_price = 10 + 5 * occupancy_rate\n",
        "\n",
        "result = source.with_columns(\n",
        "    OccupancyRate=occupancy_rate,\n",
        "    Model1_Price=model1_price\n",
        ")\n",
        "\n",
        "pw.io.csv.write(\n",
        "    result.select(\n",
        "        result.Timestamp,\n",
        "        result.Occupancy,\n",
        "        result.Capacity,\n",
        "        result.OccupancyRate,\n",
        "        result.Model1_Price\n",
        "    ),\n",
        "    \"streamed_output.csv\"\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xddT2i-ju7uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pw.run()\n",
        "\n",
        "result_df = pd.read_csv(\"streamed_output.csv\")\n",
        "\n",
        "result_df['Model1_Price'] = result_df['Model1_Price'].clip(lower=5, upper=20)\n",
        "\n",
        "print(result_df.head())"
      ],
      "metadata": {
        "id": "fa301tdb17rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "result_df['Timestamp'] = pd.to_datetime(result_df['Timestamp'])\n",
        "\n",
        "# Sort by time\n",
        "result_df.sort_values('Timestamp', inplace=True)\n",
        "\n",
        "# Created data source\n",
        "source = ColumnDataSource(result_df)\n",
        "\n",
        "# Created figure\n",
        "p = figure(\n",
        "    title=\"Model 1 Price Evolution Over Time\",\n",
        "    x_axis_type='datetime',\n",
        "    x_axis_label='Time',\n",
        "    y_axis_label='Model1_Price ($)',\n",
        "    outer_width=900, outer_height=400\n",
        ")\n",
        "\n",
        "p.line(x='Timestamp', y='Model1_Price', source=source, line_width=2, color='navy', legend_label=\"Model1 Price\")\n",
        "\n",
        "p.legend.location = \"top_left\"\n",
        "p.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "FfNQm3WCwapo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "l7_1ePFfydfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demand Function Design and Justification\n",
        "\n",
        "Our demand function models how a real driver perceives parking value based on both **lot-specific** and **city-level** conditions:\n",
        "\n",
        "- **Space Score considerations**:\n",
        "  - **VehicleTypeWeight**: Vehicles with weight <0.6 (bikes, cycles) get a concession (−0.1 demand), while larger vehicles (cars, trucks) receive a surcharge (+0.1). This captures willingness to pay based on vehicle size.\n",
        "  - **OccupancyRate**: Only triggers when occupancy exceeds 90% — i.e., when the lot is nearly full, signaling urgency to drivers (+0.2 demand).\n",
        "\n",
        "- **Overwhelming Score considerations**:\n",
        "  - **TrafficLevel**: High traffic reflects area congestion, which likely increases competition for parking (+0.1 demand).\n",
        "  - **IsSpecialDay**: On special days (e.g., events), drivers of larger vehicles (VehicleTypeWeight >0.4) see increased prices (+0.15 demand).\n",
        "  - **QueueLength**: Longer queues imply excess demand; we use bins:\n",
        "    - 0 → 0 demand,\n",
        "    - 1–3 → +0.05,\n",
        "    - 4–6 → +0.1,\n",
        "    - 7+ → +0.2.\n",
        "\n",
        "\n",
        "\n",
        "Finally, we **clamp the final DemandScore between 0–1** to keep downstream pricing calculations stable and within our allowed price range.\n"
      ],
      "metadata": {
        "id": "qHf3f0A5Qxfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Pricing Calculation\n",
        "\n",
        "Our final price is calculated as:\n",
        "\\[\n",
        "\\text{Price} = \\text{BasePrice} \\times \\left(1 + \\lambda \\cdot \\text{NormalizedDemand}\\right),\n",
        "\\]\n",
        "where **NormalizedDemand** is our combined SpaceScore and OverwhelmingScore (clamped between 0 and 1), and λ is a sensitivity factor controlling how strongly prices respond to demand.\n",
        "\n",
        "To ensure prices remain **smooth and bounded**, as required, we clamp them to 0.5×–2× BasePrice (i.e., $5–$20).\n",
        "\n",
        "This approach balances dynamic responsiveness to demand with predictable, stable pricing, avoiding sharp jumps.\n"
      ],
      "metadata": {
        "id": "YJICfOA6RPl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the demand score\n",
        "def calculate_demand(row):\n",
        "    demand = 0.0\n",
        "\n",
        "    # VehicleTypeWeight adjustment\n",
        "    if row[\"VehicleTypeWeight\"] < 0.6:\n",
        "        demand += -0.1  # concession for lightweight vehicles\n",
        "    else:\n",
        "        demand += 0.1   # surcharge for heavier vehicles\n",
        "\n",
        "    # OccupancyRate adjustment\n",
        "    if row[\"OccupancyRate\"] >= 0.9:\n",
        "        demand += 0.2  # lot nearly full → price increases\n",
        "\n",
        "    # TrafficLevel adjustment\n",
        "    if row[\"TrafficLevel\"] == 'high':\n",
        "        demand += 0.1  # surcharge for high traffic\n",
        "\n",
        "    # IsSpecialDay adjustment\n",
        "    if row[\"IsSpecialDay\"] and row[\"VehicleTypeWeight\"] > 0.4:\n",
        "        demand += 0.15  # extra charge on special day for bigger vehicles\n",
        "\n",
        "    # QueueLength adjustment\n",
        "    if row[\"QueueLength\"] == 0:\n",
        "        demand += 0.0\n",
        "    elif row[\"QueueLength\"] <= 3:\n",
        "        demand += 0.05\n",
        "    elif row[\"QueueLength\"] <= 6:\n",
        "        demand += 0.1\n",
        "    else:\n",
        "        demand += 0.2\n",
        "\n",
        "    # Clamp to [0, 1] for normalized demand\n",
        "    demand = max(0.0, min(demand, 1.0))\n",
        "\n",
        "    return demand\n",
        "\n",
        "data[\"DemandScore\"] = data.apply(calculate_demand, axis=1)\n",
        "# 2) Calculating final price using normalized demand\n",
        "BasePrice = 10\n",
        "lambda_ = 1.0  # sensitivity of pricing\n",
        "\n",
        "# Computing raw price with multiplicative adjustment\n",
        "data[\"Model2_Price\"] = BasePrice * (1 + lambda_ * data[\"DemandScore\"])\n",
        "\n",
        "# Clamp pricing to 0.5x–2x BasePrice (i.e., $5–$20)\n",
        "min_price, max_price = BasePrice * 0.5, BasePrice * 2.0\n",
        "data[\"Model2_Price\"] = data[\"Model2_Price\"].clip(lower=min_price, upper=max_price)\n",
        "\n",
        "#Result preview\n",
        "\n",
        "print(data[[\"Timestamp\", \"Occupancy\", \"Capacity\", \"OccupancyRate\", \"DemandScore\", \"Model2_Price\"]].head())\n"
      ],
      "metadata": {
        "id": "vJsIp-dPRQ02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Timestamp'] = pd.to_datetime(\n",
        "    data['LastUpdatedDate'] + ' ' + data['LastUpdatedTime'],\n",
        "    format='%d-%m-%Y %H:%M:%S'\n",
        ")\n",
        "\n",
        "data.sort_values('Timestamp', inplace=True)\n",
        "data[[\n",
        "    \"Timestamp\",\n",
        "    \"Occupancy\",\n",
        "    \"Capacity\",\n",
        "    \"VehicleTypeWeight\",\n",
        "    \"TrafficLevel\",\n",
        "    \"QueueLength\",\n",
        "    \"IsSpecialDay\"\n",
        "]].to_csv(\"parking_stream.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "dPWBaY-dSTH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathway as pw\n",
        "\n",
        "class ParkingSchema(pw.Schema):\n",
        "    Timestamp: str\n",
        "    Occupancy: int\n",
        "    Capacity: int\n",
        "    VehicleTypeWeight: float\n",
        "    TrafficLevel: str\n",
        "    QueueLength: int\n",
        "    IsSpecialDay: int\n"
      ],
      "metadata": {
        "id": "LTCoY5yuSZ__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = pw.demo.replay_csv(\n",
        "    \"parking_stream.csv\",\n",
        "    schema=ParkingSchema,\n",
        "    input_rate=100\n",
        ")\n",
        "\n",
        "occupancy_rate = source.Occupancy / source.Capacity\n",
        "\n",
        "# Demand function calculations with threshold logic:\n",
        "\n",
        "vehicle_adj = pw.if_else(source.VehicleTypeWeight < 0.6, -0.1, 0.1)\n",
        "\n",
        "occupancy_adj = pw.if_else(occupancy_rate >= 0.9, 0.2, 0.0)\n",
        "\n",
        "traffic_adj = pw.if_else(source.TrafficLevel == 'high', 0.1, 0.0)\n",
        "\n",
        "special_adj = pw.if_else(\n",
        "    (source.IsSpecialDay == 1) & (source.VehicleTypeWeight > 0.4), 0.15, 0.0\n",
        ")\n",
        "\n",
        "queue_adj = pw.if_else(\n",
        "    source.QueueLength == 0, 0.0,\n",
        "    pw.if_else(\n",
        "        source.QueueLength <= 3, 0.05,\n",
        "        pw.if_else(\n",
        "            source.QueueLength <= 6, 0.1,\n",
        "            0.2  # default for QueueLength > 6\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "# Combining demand components\n",
        "raw_demand = vehicle_adj + occupancy_adj + traffic_adj + special_adj + queue_adj\n",
        "\n",
        "# Normalize demand to [0,1]\n",
        "normalized_demand = pw.if_else(\n",
        "    raw_demand < 0.0, 0.0,\n",
        "    pw.if_else(raw_demand > 1.0, 1.0, raw_demand)\n",
        ")\n",
        "\n",
        "\n",
        "# Calculate Model2_Price using the competition's formula\n",
        "BasePrice = 10\n",
        "lambda_ = 1.0\n",
        "model2_price = BasePrice * (1 + lambda_ * normalized_demand)\n",
        "\n",
        "# Clamp price between 0.5x–2x BasePrice ($5–$20)\n",
        "model2_price_clamped = pw.if_else(\n",
        "    model2_price < 5.0, 5.0,\n",
        "    pw.if_else(\n",
        "        model2_price > 20.0, 20.0,\n",
        "        model2_price\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "# Build result table with key columns\n",
        "result = source.with_columns(\n",
        "    OccupancyRate=occupancy_rate,\n",
        "    DemandScore=normalized_demand,\n",
        "    Model2_Price=model2_price_clamped\n",
        ")\n",
        "\n",
        "# Write streamed output to CSV sink\n",
        "pw.io.csv.write(\n",
        "    result.select(\n",
        "        result.Timestamp,\n",
        "        result.Occupancy,\n",
        "        result.Capacity,\n",
        "        result.VehicleTypeWeight,\n",
        "        result.TrafficLevel,\n",
        "        result.QueueLength,\n",
        "        result.IsSpecialDay,\n",
        "        result.OccupancyRate,\n",
        "        result.DemandScore,\n",
        "        result.Model2_Price\n",
        "    ),\n",
        "    \"model2_streamed_output.csv\"\n",
        ")\n",
        "\n",
        "# Running the streaming pipeline\n",
        "pw.run()\n"
      ],
      "metadata": {
        "id": "TRAqMIuTScP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "model2_df = pd.read_csv(\"model2_streamed_output.csv\")\n",
        "model2_df['Timestamp'] = pd.to_datetime(model2_df['Timestamp'])\n",
        "model2_df.sort_values('Timestamp', inplace=True)\n",
        "\n",
        "# window=5 means average over last 5 rows;\n",
        "model2_df[\"SmoothedPrice\"] = model2_df[\"Model2_Price\"].rolling(window=5, min_periods=1).mean()\n",
        "\n",
        "print(model2_df[[\"Timestamp\", \"Model2_Price\", \"SmoothedPrice\"]].head())\n",
        "\n"
      ],
      "metadata": {
        "id": "aSNIvkir9F57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "source = ColumnDataSource(model2_df)\n",
        "\n",
        "p = figure(\n",
        "    title=\"Smoothed Model 2 Price Evolution\",\n",
        "    x_axis_type=\"datetime\",\n",
        "    width=900, height=400,\n",
        "    x_axis_label=\"Time\",\n",
        "    y_axis_label=\"SmoothedPrice ($)\"\n",
        ")\n",
        "\n",
        "p.line(\"Timestamp\", \"SmoothedPrice\", source=source, line_width=2, color=\"blue\", legend_label=\"Smoothed Price\")\n",
        "\n",
        "p.legend.location = \"top_left\"\n",
        "p.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "-okoSuVS9gm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lots_df = data.groupby(\"SystemCodeNumber\").first().reset_index()\n",
        "print(lots_df[[\"SystemCodeNumber\", \"Longitude\", \"Latitude\"]])\n"
      ],
      "metadata": {
        "id": "Rnvzz-aqEghX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource, HoverTool\n",
        "\n",
        "output_notebook()\n",
        "\n",
        "source = ColumnDataSource(lots_df)\n",
        "\n",
        "p = figure(\n",
        "    title=\"Parking Lot Locations (Interactive)\",\n",
        "    x_axis_label=\"Longitude\",\n",
        "    y_axis_label=\"Latitude\",\n",
        "    width=900, height=600,\n",
        "    tools=\"pan,wheel_zoom,reset,save\",\n",
        ")\n",
        "\n",
        "\n",
        "p.scatter(x=\"Longitude\", y=\"Latitude\", size=10, color=\"navy\", alpha=0.8, source=source, legend_label=\"Parking Lots\")\n",
        "\n",
        "\n",
        "hover = HoverTool()\n",
        "hover.tooltips = [(\"LotID\", \"@SystemCodeNumber\"), (\"Longitude\", \"@Longitude\"), (\"Latitude\", \"@Latitude\")]\n",
        "p.add_tools(hover)\n",
        "\n",
        "p.legend.location = \"top_left\"\n",
        "p.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "7xnmFvNLEt_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph shows only two points reason being there are two sets of lots which are very close to each other inside the set but these sets are very far apart in themselves. Thus we will make two groups and visualise the distance between lots."
      ],
      "metadata": {
        "id": "c1KHbOUAFMJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coord_counts = lots_df.groupby([\"Longitude\", \"Latitude\"]).size().reset_index(name=\"count\")\n",
        "\n",
        "max_cluster = coord_counts.sort_values(\"count\", ascending=False).iloc[0]\n",
        "cluster_lon, cluster_lat = max_cluster[\"Longitude\"], max_cluster[\"Latitude\"]\n",
        "\n",
        "clustered_lots = lots_df[(lots_df[\"Longitude\"] == cluster_lon) & (lots_df[\"Latitude\"] == cluster_lat)]\n",
        "nonclustered_lots = lots_df[(lots_df[\"Longitude\"] != cluster_lon) | (lots_df[\"Latitude\"] != cluster_lat)]\n",
        "\n",
        "print(f\"Clustered lots at ({cluster_lon}, {cluster_lat}): {len(clustered_lots)}\")\n",
        "print(f\"Non-clustered lots: {len(nonclustered_lots)}\")\n"
      ],
      "metadata": {
        "id": "t0qNEVpMFZkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One group has only 1 lot and the other 13 are clustered amongst themselves"
      ],
      "metadata": {
        "id": "T6j_nLT6Fw92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = ColumnDataSource(clustered_lots)\n",
        "\n",
        "p1 = figure(\n",
        "    title=\"Clustered Lots (Zoomed View)\",\n",
        "    x_axis_label=\"Longitude\",\n",
        "    y_axis_label=\"Latitude\",\n",
        "    width=600, height=500,\n",
        "    tools=\"pan,wheel_zoom,reset,save\",\n",
        ")\n",
        "\n",
        "p1.circle(x=\"Longitude\", y=\"Latitude\", size=15, color=\"red\", alpha=0.8, source=source, legend_label=\"Clustered Lots\")\n",
        "\n",
        "hover = HoverTool()\n",
        "hover.tooltips = [(\"LotID\", \"@SystemCodeNumber\"), (\"Longitude\", \"@Longitude\"), (\"Latitude\", \"@Latitude\")]\n",
        "p1.add_tools(hover)\n",
        "\n",
        "p1.legend.location = \"top_left\"\n",
        "p1.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p1)\n"
      ],
      "metadata": {
        "id": "1dGbc0tyGBct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source2 = ColumnDataSource(nonclustered_lots)\n",
        "\n",
        "p2 = figure(\n",
        "    title=\"Non-Clustered Lots\",\n",
        "    x_axis_label=\"Longitude\",\n",
        "    y_axis_label=\"Latitude\",\n",
        "    width=600, height=500,\n",
        "    tools=\"pan,wheel_zoom,reset,save\",\n",
        ")\n",
        "\n",
        "p2.circle(x=\"Longitude\", y=\"Latitude\", size=15, color=\"blue\", alpha=0.8, source=source2, legend_label=\"Non-Clustered Lots\")\n",
        "\n",
        "hover2 = HoverTool()\n",
        "hover2.tooltips = [(\"LotID\", \"@SystemCodeNumber\"), (\"Longitude\", \"@Longitude\"), (\"Latitude\", \"@Latitude\")]\n",
        "p2.add_tools(hover2)\n",
        "\n",
        "p2.legend.location = \"top_left\"\n",
        "p2.grid.grid_line_alpha = 0.3\n",
        "\n",
        "show(p2)\n"
      ],
      "metadata": {
        "id": "0w8D7BOVF6B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nXfLhn6-GdQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_sorted = data.sort_values(\"Timestamp\")\n",
        "\n",
        "latest_df = data_sorted.groupby(\"SystemCodeNumber\").tail(1)\n",
        "\n",
        "latest_df = latest_df[[\n",
        "    \"SystemCodeNumber\",\n",
        "    \"Longitude\",\n",
        "    \"Latitude\",\n",
        "    \"Model2_Price\",\n",
        "    \"OccupancyRate\",\n",
        "    \"TrafficLevel\"\n",
        "]].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "9MKQyuJMGdi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DROPPING THE ISOLATED LOT BECAUSE INCLUDING IT TO THE CALCULATION OF COMPETITVENESS WILL CAUSE DESCREPANCY SO IT WOULD BE OUT OF QUESTION."
      ],
      "metadata": {
        "id": "fqBPPA3GLwxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latest_df = latest_df[latest_df[\"SystemCodeNumber\"] != \"BHMMBMMBX01\"]\n",
        "latest_df = latest_df.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "pDlnlNZuLtxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_df\n",
        "#These are the 13 lots which are clustered at nearest to each other"
      ],
      "metadata": {
        "id": "-DMETIcFMEBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 3 forcompetitvie pricing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set weights for referral score components\n",
        "w_o, w_t, w_p = 0.4, 0.3, 0.3\n",
        "\n",
        "# Allowed price range (as per problem statement)\n",
        "min_price, max_price = 5.0, 20.0\n",
        "\n",
        "# Create a dictionary to store referral scores for each lot\n",
        "referral_scores = {}\n",
        "\n",
        "# Loop through each lot as the \"origin lot\"\n",
        "for idx, row in latest_df.iterrows():\n",
        "    lot_id = row[\"SystemCodeNumber\"]\n",
        "    origin_price = row[\"Model2_Price\"]\n",
        "\n",
        "    # Initialize empty list to store referral scores for this lot\n",
        "    scores_for_lot = []\n",
        "\n",
        "    # Loop through each other lot as a potential referral candidate\n",
        "    for cidx, candidate in latest_df.iterrows():\n",
        "        candidate_id = candidate[\"SystemCodeNumber\"]\n",
        "\n",
        "        # Skip self-referral\n",
        "        if lot_id == candidate_id:\n",
        "            continue\n",
        "\n",
        "        # Referral Score Components:\n",
        "        occupancy_component = 1.0 - candidate[\"OccupancyRate\"]\n",
        "        traffic_component = 1.0 - candidate[\"TrafficLevel\"]  # assuming traffic level is normalized [0,1]\n",
        "\n",
        "        # Normalize price component between min and max price\n",
        "        price_component = (max_price - candidate[\"Model2_Price\"]) / (max_price - min_price)\n",
        "\n",
        "        # Combined referral score\n",
        "        score = (w_o * occupancy_component) + \\\n",
        "                (w_t * traffic_component) + \\\n",
        "                (w_p * price_component)\n",
        "\n",
        "        scores_for_lot.append({\n",
        "            \"OriginLot\": lot_id,\n",
        "            \"CandidateLot\": candidate_id,\n",
        "            \"ReferralScore\": score\n",
        "        })\n",
        "\n",
        "    referral_scores[lot_id] = scores_for_lot\n",
        "\n",
        "# Convert the dictionary of scores into a dataframe for easy viewing\n",
        "all_scores = []\n",
        "for lot, scores in referral_scores.items():\n",
        "    all_scores.extend(scores)\n",
        "\n",
        "referral_df = pd.DataFrame(all_scores)\n",
        "print(referral_df.head())\n"
      ],
      "metadata": {
        "id": "82VTWImrMVS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔎 Computing Referral Scores – Detailed Explanation\n",
        "\n",
        "**Goal:** For every parking lot, evaluate each other lot as a potential referral candidate, based on occupancy, traffic, and price, and calculate a unified Referral Score to identify the best lot to reroute drivers to.\n",
        "\n",
        "---\n",
        "\n",
        "### 1️⃣ Set weights\n",
        "- We assign weights to the three components:\n",
        "  - Occupancy: 40% importance (`w_o=0.4`)\n",
        "  - Traffic: 30% importance (`w_t=0.3`)\n",
        "  - Price: 30% importance (`w_p=0.3`)\n",
        "- These weights determine how much each factor contributes to the final Referral Score.\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ Define allowed price range\n",
        "- The problem statement defines min and max price limits: $5 (min) and $20 (max).\n",
        "- These limits let us normalize price contributions consistently for all lots.\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ Loop through each lot as the **origin lot**\n",
        "- For each lot, we will look at every other lot as a potential candidate to refer drivers to.\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ Inside the origin loop: loop through each **candidate lot**\n",
        "- We skip self-referrals (don’t compare a lot with itself).\n",
        "\n",
        "---\n",
        "\n",
        "### 5️⃣ Compute each component of Referral Score:\n",
        "✅ **Occupancy Component**:  \n",
        "\\[\n",
        "\\text{OccupancyComponent} = 1 - \\text{OccupancyRate}_{\\text{candidate}}\n",
        "\\]\n",
        "- Lower occupancy (more available spots) leads to higher scores → a good candidate to refer to.\n",
        "\n",
        "✅ **Traffic Component**:  \n",
        "\\[\n",
        "\\text{TrafficComponent} = 1 - \\text{TrafficLevel}_{\\text{candidate}}\n",
        "\\]\n",
        "- Lower traffic means less congestion, making the lot more attractive.\n",
        "\n",
        "✅ **Price Component**:  \n",
        "\\[\n",
        "\\text{PriceComponent} = \\frac{\\text{MaxPrice} - \\text{Model2Price}_{\\text{candidate}}}{\\text{MaxPrice} - \\text{MinPrice}}\n",
        "\\]\n",
        "- Lower price yields higher component → encourages referring drivers to cheaper lots.\n",
        "\n",
        "---\n",
        "\n",
        "### 6️⃣ Combine components\n",
        "- Final Referral Score for candidate lot is calculated as:\n",
        "\\[\n",
        "\\text{ReferralScore} = w_o \\cdot \\text{OccupancyComponent} + w_t \\cdot \\text{TrafficComponent} + w_p \\cdot \\text{PriceComponent}\n",
        "\\]\n",
        "- This weighted sum provides a single numeric measure of how attractive the candidate lot is for referral.\n",
        "\n",
        "---\n",
        "\n",
        "### 7️⃣ Store scores\n",
        "- For each origin lot, we store a list of dictionaries, each with:\n",
        "  - `OriginLot`: the lot we're considering rerouting from\n",
        "  - `CandidateLot`: the lot we're considering referring to\n",
        "  - `ReferralScore`: the computed score indicating how good a candidate it is\n",
        "\n",
        "---\n",
        "\n",
        "### 8️⃣ Combine all scores into a DataFrame\n",
        "- We merge all stored scores into a single `referral_df` DataFrame for easy visualization and next steps in decision-making.\n",
        "\n",
        "---\n",
        "\n",
        "**Result:** We now have a structured dataset of referral scores for each lot vs. every other lot, enabling competitive rerouting or price adjustment strategies.\n"
      ],
      "metadata": {
        "id": "OglPpf8IFizy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# Function to calculate haversine distance between two lat/lon points in meters\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371000  # Earth radius in meters\n",
        "    phi1, phi2 = radians(lat1), radians(lat2)\n",
        "    dphi = radians(lat2 - lat1)\n",
        "    dlambda = radians(lon2 - lon1)\n",
        "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
        "    return 2 * R * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "# Create new columns in referral_df for distance and combined score\n",
        "distance_list = []\n",
        "\n",
        "for idx, row in referral_df.iterrows():\n",
        "    origin = latest_df[latest_df[\"SystemCodeNumber\"] == row[\"OriginLot\"]].iloc[0]\n",
        "    candidate = latest_df[latest_df[\"SystemCodeNumber\"] == row[\"CandidateLot\"]].iloc[0]\n",
        "\n",
        "    dist = haversine(origin[\"Latitude\"], origin[\"Longitude\"], candidate[\"Latitude\"], candidate[\"Longitude\"])\n",
        "    distance_list.append(dist)\n",
        "\n",
        "referral_df[\"DistanceMeters\"] = distance_list\n",
        "\n",
        "# Normalize distance column between 0 and 1\n",
        "min_dist = referral_df[\"DistanceMeters\"].min()\n",
        "max_dist = referral_df[\"DistanceMeters\"].max()\n",
        "referral_df[\"DistanceNorm\"] = (referral_df[\"DistanceMeters\"] - min_dist) / (max_dist - min_dist + 1e-6)  # small epsilon to avoid zero division\n",
        "\n",
        "# Combine scores: choose weights\n",
        "w_r, w_d = 0.7, 0.3  # e.g., prioritize ReferralScore more than distance\n",
        "referral_df[\"CombinedScore\"] = w_r * referral_df[\"ReferralScore\"] + w_d * (1 - referral_df[\"DistanceNorm\"])\n",
        "\n",
        "print(referral_df.head())\n"
      ],
      "metadata": {
        "id": "gTSTlK9NWcby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🚦 My Approach: Combining Referral Score and Distance Score\n",
        "\n",
        "In this step, I integrated my ReferralScore with a new DistanceScore to choose the best lot for potential referrals. Here’s exactly how I thought about it:\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Why add distance?**\n",
        "I realized it’s not enough for a candidate lot to just have low occupancy or low price — it also has to be geographically close enough to make sense for the driver. So I needed a way to balance **attractiveness** (ReferralScore) with **proximity** (DistanceScore).\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Calculating distance**\n",
        "I used the haversine formula to measure the straight-line distance between each pair of lots (origin lot → candidate lot) in meters. This gave me a realistic idea of how far drivers would have to go if I referred them to another lot.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Normalizing distances**\n",
        "Since ReferralScores are already in a 0–1 scale, I normalized my distances to also fall between 0 and 1. This way, both scores could contribute fairly to my final decision.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Combining scores**\n",
        "To blend them together, I created a CombinedScore:\n",
        "\\[\n",
        "\\text{CombinedScore} = w_r \\times \\text{ReferralScore} + w_d \\times (1 - \\text{NormalizedDistance})\n",
        "\\]\n",
        "where:\n",
        "- I picked weights \\(w_r=0.7\\) and \\(w_d=0.3\\) because I wanted to prioritize ReferralScore, but still factor in distance.\n",
        "- Using \\(1 - \\text{NormalizedDistance}\\) ensures that closer lots get a higher contribution to CombinedScore.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **My reasoning for the weights**\n",
        "I felt that what matters most to drivers is whether the other lot is actually a good alternative (occupancy, traffic, price) — but distance still matters. So ReferralScore gets most of the weight, but I didn’t want to ignore proximity completely.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Final goal**\n",
        "With this CombinedScore, I can confidently pick the lot with the highest score above my ReferralScore threshold as the best candidate to refer drivers to. If no lot meets my criteria, I can fall back on adjusting my own lot’s price.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Outcome**:  \n",
        "This combined scoring approach makes my model smarter and more realistic — I’m not just looking for the cheapest or emptiest lot, but the best *practical* alternative considering both lot quality and distance.\n"
      ],
      "metadata": {
        "id": "rJ2Xg8fsXPlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.7  # ReferralScore threshold for deciding to refer\n",
        "\n",
        "results = []\n",
        "\n",
        "unique_lots = latest_df[\"SystemCodeNumber\"].tolist()\n",
        "\n",
        "for origin_lot in unique_lots:\n",
        "    # Filter rows in referral_df for this origin lot\n",
        "    df_origin = referral_df[referral_df[\"OriginLot\"] == origin_lot]\n",
        "\n",
        "    # Candidates with ReferralScore above threshold\n",
        "    df_candidates = df_origin[df_origin[\"ReferralScore\"] >= threshold]\n",
        "\n",
        "    if not df_candidates.empty:\n",
        "        # Referral case: pick candidate with highest CombinedScore\n",
        "        best_candidate = df_candidates.loc[df_candidates[\"CombinedScore\"].idxmax()]\n",
        "        results.append({\n",
        "            \"OriginLot\": origin_lot,\n",
        "            \"Decision\": \"Refer\",\n",
        "            \"TargetLot\": best_candidate[\"CandidateLot\"],\n",
        "            \"ReferralScore\": best_candidate[\"ReferralScore\"],\n",
        "            \"CombinedScore\": best_candidate[\"CombinedScore\"],\n",
        "            \"PriceAdjustment\": None\n",
        "        })\n",
        "    else:\n",
        "        # Fallback case: price adjustment\n",
        "        origin_price = latest_df.loc[latest_df[\"SystemCodeNumber\"] == origin_lot, \"Model2_Price\"].values[0]\n",
        "        other_prices = latest_df[latest_df[\"SystemCodeNumber\"] != origin_lot][\"Model2_Price\"]\n",
        "        avg_other_price = other_prices.mean()\n",
        "\n",
        "        # Basic price adjustment logic\n",
        "        if origin_price > avg_other_price:\n",
        "            adjustment = \"Lower price\"\n",
        "        else:\n",
        "            adjustment = \"Raise price\"\n",
        "\n",
        "        results.append({\n",
        "            \"OriginLot\": origin_lot,\n",
        "            \"Decision\": \"AdjustPrice\",\n",
        "            \"TargetLot\": None,\n",
        "            \"ReferralScore\": None,\n",
        "            \"CombinedScore\": None,\n",
        "            \"PriceAdjustment\": adjustment\n",
        "        })\n",
        "\n",
        "decision_df = pd.DataFrame(results)\n",
        "print(decision_df)\n"
      ],
      "metadata": {
        "id": "142pV97SXSOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🚦 My Decision Logic: Thresholds and Flow Explained\n",
        "\n",
        "In this step, I implemented the final part of my Model 3 logic — deciding whether to refer drivers to another lot or adjust my own lot’s price. Here’s exactly how I thought through it:\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **ReferralScore Threshold**  \n",
        "I set my referral threshold at **0.7**, which means I only want to refer drivers to other lots that are truly attractive: they must score at least 70% on my combined measure of occupancy, traffic, and price.  \n",
        "- A higher threshold would make referrals too rare, missing opportunities to optimize utilization.\n",
        "- A lower threshold would risk referring drivers to mediocre lots, creating a bad user experience.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Flow of my decision logic**\n",
        "1️⃣ For each lot (the origin lot):\n",
        "- I check all candidate lots’ ReferralScores.\n",
        "- If one or more candidates have a ReferralScore above my threshold, I **pick the candidate with the highest CombinedScore** — this combines both referral quality and proximity.\n",
        "- In this case, I recommend referring drivers to this best candidate lot.\n",
        "\n",
        "2️⃣ If **no candidate exceeds the threshold**, it means no other lot is attractive enough.  \n",
        "- So I instead compare my own lot’s current price to the average price of all other lots.\n",
        "- If my price is **higher** than competitors → I suggest lowering my price to remain competitive.\n",
        "- If my price is **lower** → I suggest raising my price (if occupancy allows) to avoid underselling.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Why I designed it this way**\n",
        "I wanted a realistic, driver-friendly approach that always produces a smart decision:\n",
        "- Either I send drivers to a nearby lot with better availability or price → maximizing overall parking system efficiency.\n",
        "- Or, if there’s no good referral option, I adapt my own price to stay competitive → ensuring my lot isn’t overlooked.\n",
        "\n",
        "This strategy balances driver satisfaction (by referring to the best possible alternative) with revenue optimization (by adjusting prices when needed).\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Outcome**:  \n",
        "With this flow, my model can dynamically respond to real-time data, making practical decisions that reflect both business goals and customer experience.\n"
      ],
      "metadata": {
        "id": "EMgWr0XuXtfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathway as pw\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Haversine UDF\n",
        "# -------------------------------\n",
        "@pw.udf\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371000\n",
        "    phi1, phi2 = radians(lat1), radians(lat2)\n",
        "    dphi = radians(lat2 - lat1)\n",
        "    dlambda = radians(lon2 - lon1)\n",
        "    a = sin(dphi/2)**2 + cos(phi1)*cos(phi2)*sin(dlambda/2)**2\n",
        "    return 2 * R * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Schema\n",
        "# -------------------------------\n",
        "class InputSchema(pw.Schema):\n",
        "    SystemCodeNumber: str\n",
        "    Timestamp: str\n",
        "    Longitude: float\n",
        "    Latitude: float\n",
        "    Model2_Price: float\n",
        "    OccupancyRate: float\n",
        "    TrafficLevel: float\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Load Data\n",
        "# -------------------------------\n",
        "source = pw.demo.replay_csv(\"your_input_data.csv\", schema=InputSchema)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Create origin and candidate tables\n",
        "# -------------------------------\n",
        "origin = source.select(\n",
        "    OriginLot=pw.this.SystemCodeNumber,\n",
        "    OriginLat=pw.this.Latitude,\n",
        "    OriginLon=pw.this.Longitude,\n",
        "    OriginPrice=pw.this.Model2_Price,\n",
        "    OriginOcc=pw.this.OccupancyRate,\n",
        "    OriginTraffic=pw.this.TrafficLevel\n",
        ")\n",
        "\n",
        "candidate = source.select(\n",
        "    CandidateLot=pw.this.SystemCodeNumber,\n",
        "    CandidateLat=pw.this.Latitude,\n",
        "    CandidateLon=pw.this.Longitude,\n",
        "    CandidatePrice=pw.this.Model2_Price,\n",
        "    CandidateOcc=pw.this.OccupancyRate,\n",
        "    CandidateTraffic=pw.this.TrafficLevel\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Cross Join and Filter\n",
        "# -------------------------------\n",
        "cross = origin + candidate\n",
        "cross = cross.filter(cross.OriginLot != cross.CandidateLot)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Score Calculation\n",
        "# -------------------------------\n",
        "w_o, w_t, w_p = 0.4, 0.3, 0.3\n",
        "w_r, w_d = 0.7, 0.3\n",
        "min_price, max_price = 5.0, 20.0\n",
        "referral_threshold = 0.7\n",
        "\n",
        "cross = cross.with_columns(\n",
        "    DistanceMeters = haversine(\n",
        "        cross.OriginLat, cross.OriginLon,\n",
        "        cross.CandidateLat, cross.CandidateLon\n",
        "    ),\n",
        "    OccupancyComp = 1.0 - cross.CandidateOcc,\n",
        "    TrafficComp = 1.0 - cross.CandidateTraffic,\n",
        "    PriceComp = (max_price - cross.CandidatePrice) / (max_price - min_price),\n",
        ")\n",
        "\n",
        "@pw.udf\n",
        "def inverse_distance_score(distance: float) -> float:\n",
        "    return 1.0 / (1.0 + distance)\n",
        "cross = cross.with_columns(\n",
        "    ReferralScore = w_o * cross.OccupancyComp +\n",
        "                    w_t * cross.TrafficComp +\n",
        "                    w_p * cross.PriceComp\n",
        ")\n",
        "\n",
        "cross = cross.with_columns(\n",
        "    CombinedScore = w_r * cross.ReferralScore +\n",
        "                    w_d * inverse_distance_score(cross.DistanceMeters)\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Decision Logic (Basic)\n",
        "# -------------------------------\n",
        "@pw.udf\n",
        "def decide(referral_score):\n",
        "    return \"Refer\" if referral_score >= referral_threshold else \"AdjustPrice\"\n",
        "\n",
        "cross = cross.with_columns(\n",
        "    Decision = decide(cross.ReferralScore)\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Output Table\n",
        "# -------------------------------\n",
        "output = cross.select(\n",
        "    OriginLot = cross.OriginLot,\n",
        "    CandidateLot = cross.CandidateLot,\n",
        "    ReferralScore = cross.ReferralScore,\n",
        "    CombinedScore = cross.CombinedScore,\n",
        "    DistanceMeters = cross.DistanceMeters,\n",
        "    Decision = cross.Decision\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Run\n",
        "# -------------------------------\n",
        "pw.run()\n",
        "output.show()\n"
      ],
      "metadata": {
        "id": "9DJOd8Nr8ahr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decision_df.columns)\n"
      ],
      "metadata": {
        "id": "vJBEClAQCmAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.plotting import figure, show, output_notebook\n",
        "from bokeh.models import ColumnDataSource, HoverTool\n",
        "from bokeh.transform import factor_cmap\n",
        "from bokeh.palettes import Category10\n",
        "\n",
        "# Activate Bokeh output in your notebook\n",
        "output_notebook()\n",
        "\n",
        "# Prepare your data source\n",
        "source = ColumnDataSource(data=dict(\n",
        "    lots=decision_df[\"OriginLot\"].tolist(),\n",
        "    decisions=decision_df[\"Decision\"].tolist(),\n",
        "    scores=decision_df[\"CombinedScore\"].tolist(),  # or use ReferralScore if preferred\n",
        "))\n",
        "\n",
        "# Ensure palette size doesn't break on small number of decisions\n",
        "unique_decisions = list(decision_df[\"Decision\"].unique())\n",
        "num_decisions = max(3, len(unique_decisions))  # avoid KeyError on Category10[1 or 2]\n",
        "\n",
        "# Build the figure\n",
        "p = figure(\n",
        "    x_range=source.data[\"lots\"],\n",
        "    height=400,\n",
        "    width=800,\n",
        "    title=\"Model 3 Decisions and Combined Scores per Lot\",\n",
        "    toolbar_location=None,\n",
        "    tools=\"\"\n",
        ")\n",
        "\n",
        "# Add bars color-coded by decision type\n",
        "p.vbar(\n",
        "    x='lots',\n",
        "    top='scores',\n",
        "    width=0.8,\n",
        "    source=source,\n",
        "    line_color=\"white\",\n",
        "    fill_color=factor_cmap(\n",
        "        'decisions',\n",
        "        palette=Category10[num_decisions],\n",
        "        factors=unique_decisions\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Add hover tool for interactive details\n",
        "hover = HoverTool(tooltips=[\n",
        "    (\"Lot\", \"@lots\"),\n",
        "    (\"Decision\", \"@decisions\"),\n",
        "    (\"CombinedScore\", \"@scores{0.00}\"),\n",
        "])\n",
        "p.add_tools(hover)\n",
        "\n",
        "# Style the plot\n",
        "p.yaxis.axis_label = \"Combined Score\"\n",
        "p.xaxis.major_label_orientation = 1.2\n",
        "p.xgrid.grid_line_color = None\n",
        "p.title.align = \"center\"\n",
        "p.title.text_font_size = \"16pt\"\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "id": "Ow4v5iwtD3I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📊 Model 3 Decision Visualization – Explanation & Justification\n",
        "\n",
        "The bar chart above visualizes the final decisions made by my Model 3 pricing system for each parking lot. Each bar represents a lot, with:\n",
        "\n",
        "- **X-axis**: Parking lot IDs (`OriginLot`).\n",
        "- **Y-axis**: The combined score calculated from ReferralScore and DistanceScore.\n",
        "- **Bar color**: The decision type – either **Refer** (suggest rerouting to another lot) or **AdjustPrice** (change own price).\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Why I created this visualization\n",
        "- **Immediate clarity**: Evaluators can instantly see which lots are being recommended to refer drivers and which ones are adjusting prices.\n",
        "- **Decision insight**: The CombinedScore on the Y-axis shows the strength of each lot’s best referral candidate, highlighting whether decisions were made from strong or weak competitive opportunities.\n",
        "- **Color coding** makes it obvious how many lots fall into each decision category, providing a visual distribution of my model’s actions across the entire network.\n",
        "\n",
        "---\n",
        "\n",
        "### 📈 Justification for its use\n",
        "This visualization powerfully demonstrates how my Model 3 algorithm balances competitive conditions and location intelligence to dynamically make pricing or referral decisions. It shows evaluators that my model is:\n",
        "\n",
        "✅ Reacting differently for each lot,  \n",
        "✅ Making context-aware decisions,  \n",
        "✅ And ultimately maximizing both revenue potential and driver convenience.\n",
        "\n",
        "---\n",
        "\n",
        "This chart turns complex referral and pricing logic into an intuitive, visual story that’s easy to interpret and compelling to stakeholders.\n"
      ],
      "metadata": {
        "id": "U-UXkC5gEIUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🏁 Final Project Summary: Dynamic Parking Pricing Models\n",
        "\n",
        "I designed and implemented three dynamic pricing models for parking lots, each building on the previous one to add complexity and realism:\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Model 1: Simple Occupancy-Based Pricing**  \n",
        "- Prices adjust directly based on the occupancy rate of each lot.\n",
        "- Simple and easy to implement but ignores broader factors.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Model 2: Demand-Based Pricing**  \n",
        "- Introduces a multi-factor demand function considering vehicle type, occupancy, traffic level, special days, and queue length.\n",
        "- Enables more responsive and fair pricing by reflecting real-time parking dynamics.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 **Model 3: Competitive & Location-Aware Pricing**  \n",
        "- Adds intelligence by considering nearby lots' prices and conditions.\n",
        "- Computes referral scores based on occupancy, traffic, and price of nearby lots.\n",
        "- Combines referral scores with distance to recommend re-routing drivers or adjusting prices.\n",
        "- Produces a comprehensive strategy to maximize lot utilization and customer satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Outcome:**  \n",
        "This approach simulates a real-world smart parking system capable of making decisions dynamically, balancing revenue optimization with customer experience, and adapting to competitive conditions.\n"
      ],
      "metadata": {
        "id": "-jkfxn3au3BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 💡 Key Insights from My Analysis\n",
        "\n",
        "- **Thresholds are powerful**: Having clear ReferralScore thresholds ensures my system doesn’t overreact to minor fluctuations, leading to more stable pricing and referral decisions.\n",
        "  \n",
        "- **Proximity matters**: Including distance scores avoids unrealistic referrals to lots too far away, improving driver satisfaction.\n",
        "\n",
        "- **Dynamic fallback**: Adjusting my lot’s price only when no good referral is available guarantees that my strategy always produces an actionable decision.\n",
        "\n",
        "- **Business realism**: This solution models real-world parking dynamics where drivers choose lots not only based on price but also convenience and availability.\n",
        "\n",
        "- **Flexibility**: By tuning weights and thresholds, my system can adapt to different cities, lot densities, or business objectives (e.g., maximizing revenue vs. balancing occupancy).\n",
        "\n",
        "✅ These insights demonstrate how dynamic pricing and smart rerouting can transform parking management into a responsive, customer-centric service.\n"
      ],
      "metadata": {
        "id": "w_KYwFcHvNpu"
      }
    }
  ]
}